{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae79578-788a-40a1-bf42-89eaf57e1337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,cv2,torch,torchvision\n",
    "import detectron2\n",
    "from detectron2.evaluation import COCOEvaluator,inference_context,inference_on_dataset\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import DatasetCatalog,MetadataCatalog,build_detection_test_loader\n",
    "from detectron2.engine import DefaultPredictor,DefaultTrainer\n",
    "from detectron2.model_zoo import get_checkpoint_url,get_config_file\n",
    "from detectron2.utils.video_visualizer import VideoVisualizer\n",
    "from detectron2.utils.visualizer import Visualizer,BoxMode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from xml.etree import ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb81c213-fd8d-42dc-808a-f8cb02cd286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "x_mins = []\n",
    "y_mins = []\n",
    "y_maxs = []\n",
    "x_maxs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f3ef2f-2f53-4119-bdf4-1e36ae3d4810",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in zip(os.listdir('./data/')):\n",
    "    try:\n",
    "        img = img[0]\n",
    "        tree = ElementTree.parse(f'./data/{img}')\n",
    "        root = tree.getroot()\n",
    "        for box in root.findall('.//bndbox'):\n",
    "            xmin = box.find('xmin').text\n",
    "            xmax = box.find('xmax').text\n",
    "            ymin = box.find('ymin').text\n",
    "            ymax = box.find('ymax').text\n",
    "        imgs.append('./data/' + img.replace('.xml','.jpg'))\n",
    "        x_mins.append(int(xmin))\n",
    "        x_maxs.append(int(xmax))\n",
    "        y_mins.append(int(ymin))\n",
    "        y_maxs.append(int(ymax))\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3acc5d63-8890-4af9-a5e7-9ab58152c416",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'frame':imgs,'xmin':x_mins,'xmax':x_maxs,'ymax':y_maxs,'ymin':y_mins})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f15a90e-795f-4e82-8bc6-dac6ed18439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data=data):\n",
    "    dataset = []\n",
    "    for idx in tqdm(range(len(data))):\n",
    "        record = {}\n",
    "        info = data.iloc[idx]\n",
    "        xmin,ymin,xmax,ymax = info['xmin'],info['ymin'],info['xmax'],info['ymax']\n",
    "        height,width = cv2.imread(info['frame']).shape[:2]\n",
    "        record['file_name'] = info['frame']\n",
    "        record['height'] = height\n",
    "        record['width'] = width\n",
    "        info['class_id'] = 0\n",
    "        record['cateogry_id'] = 0\n",
    "        objs = [{'bbox':[info['xmin'],info['ymin'],info['xmax'],info['ymax']],'bbox_mode':BoxMode.XYXY_ABS,'iscrowd':0,'category_id':0}]\n",
    "        record['image_id'] = idx\n",
    "        record['annotations'] = objs\n",
    "        record['class_id'] = 0\n",
    "        record['xmin'] = xmin\n",
    "        record['ymin'] = ymin\n",
    "        record['xmax'] = xmax\n",
    "        record['ymax'] = ymax\n",
    "        dataset.append(record)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0db9aef3-bad4-4ad1-a282-c8dacb65de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetCatalog.register('data',lambda : load_data())\n",
    "MetadataCatalog.get('data').set(thing_classes=['PathHole'])\n",
    "metadata = MetadataCatalog.get('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78d4d1fd-0174-4ba7-bf2c-da83ec47f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "380d3188-2304-49e6-bfc0-52d72dc18dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e13211-513b-4027-8d2c-619b38891f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mranuga-d\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">baseline</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ranuga-d/Object-Detection-Pothole-Detection\" target=\"_blank\">https://wandb.ai/ranuga-d/Object-Detection-Pothole-Detection</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ranuga-d/Object-Detection-Pothole-Detection/runs/3lwt17ws\" target=\"_blank\">https://wandb.ai/ranuga-d/Object-Detection-Pothole-Detection/runs/3lwt17ws</a><br/>\n",
       "                Run data is saved locally in <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/Object-Detection/Pothole-Detection/wandb/run-20210828_080851-3lwt17ws</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/28 08:09:03 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): ResNet(\n",
      "    (stem): BasicStem(\n",
      "      (conv1): Conv2d(\n",
      "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (res2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res4): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (4): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (5): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): Res5ROIHeads(\n",
      "    (pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (res5): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=2048, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=2048, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/665 [00:00<?, ?it/s]/home/indika/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:1056: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cacher_needs_updating = self._check_is_chained_assignment_possible()\n",
      "/home/indika/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1724: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer_missing(indexer, value)\n",
      "100%|██████████| 665/665 [00:02<00:00, 289.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/28 08:09:05 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 665 images left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/28 08:09:05 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|  PathHole  | 665          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[08/28 08:09:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/28 08:09:05 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/28 08:09:05 d2.data.common]: \u001b[0mSerializing 665 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/28 08:09:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.27 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (2, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (4, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/28 08:09:06 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:103: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  num_fg = fg_inds.nonzero().numel()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/28 08:09:14 d2.utils.events]: \u001b[0m eta: 0:22:29  iter: 19  total_loss: 1.122  loss_cls: 0.7333  loss_box_reg: 0.178  loss_rpn_cls: 0.1205  loss_rpn_loc: 0.02014  time: 0.3595  data_time: 0.0102  lr: 4.9953e-06  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:09:21 d2.utils.events]: \u001b[0m eta: 0:21:59  iter: 39  total_loss: 1.12  loss_cls: 0.6523  loss_box_reg: 0.2369  loss_rpn_cls: 0.1348  loss_rpn_loc: 0.05567  time: 0.3558  data_time: 0.0029  lr: 9.9902e-06  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:09:28 d2.utils.events]: \u001b[0m eta: 0:21:46  iter: 59  total_loss: 1.059  loss_cls: 0.4978  loss_box_reg: 0.2292  loss_rpn_cls: 0.137  loss_rpn_loc: 0.02151  time: 0.3532  data_time: 0.0029  lr: 1.4985e-05  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:09:35 d2.utils.events]: \u001b[0m eta: 0:21:44  iter: 79  total_loss: 0.8143  loss_cls: 0.3996  loss_box_reg: 0.1852  loss_rpn_cls: 0.1334  loss_rpn_loc: 0.01796  time: 0.3552  data_time: 0.0026  lr: 1.998e-05  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:09:42 d2.utils.events]: \u001b[0m eta: 0:21:25  iter: 99  total_loss: 0.7632  loss_cls: 0.3063  loss_box_reg: 0.2478  loss_rpn_cls: 0.1342  loss_rpn_loc: 0.01722  time: 0.3545  data_time: 0.0028  lr: 2.4975e-05  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:09:49 d2.utils.events]: \u001b[0m eta: 0:21:23  iter: 119  total_loss: 0.7909  loss_cls: 0.2875  loss_box_reg: 0.2849  loss_rpn_cls: 0.1634  loss_rpn_loc: 0.04059  time: 0.3558  data_time: 0.0029  lr: 2.997e-05  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:09:56 d2.utils.events]: \u001b[0m eta: 0:21:16  iter: 139  total_loss: 0.8584  loss_cls: 0.2791  loss_box_reg: 0.3042  loss_rpn_cls: 0.1322  loss_rpn_loc: 0.02119  time: 0.3566  data_time: 0.0029  lr: 3.4965e-05  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:10:04 d2.utils.events]: \u001b[0m eta: 0:21:12  iter: 159  total_loss: 0.6311  loss_cls: 0.2415  loss_box_reg: 0.2403  loss_rpn_cls: 0.109  loss_rpn_loc: 0.01628  time: 0.3569  data_time: 0.0028  lr: 3.996e-05  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:10:11 d2.utils.events]: \u001b[0m eta: 0:21:09  iter: 179  total_loss: 0.7192  loss_cls: 0.252  loss_box_reg: 0.3486  loss_rpn_cls: 0.1256  loss_rpn_loc: 0.02552  time: 0.3578  data_time: 0.0026  lr: 4.4955e-05  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:10:18 d2.utils.events]: \u001b[0m eta: 0:20:56  iter: 199  total_loss: 0.8018  loss_cls: 0.2618  loss_box_reg: 0.3943  loss_rpn_cls: 0.09856  loss_rpn_loc: 0.02483  time: 0.3565  data_time: 0.0028  lr: 4.995e-05  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:10:25 d2.utils.events]: \u001b[0m eta: 0:20:49  iter: 219  total_loss: 0.7466  loss_cls: 0.2396  loss_box_reg: 0.3129  loss_rpn_cls: 0.07765  loss_rpn_loc: 0.01262  time: 0.3576  data_time: 0.0029  lr: 5.4945e-05  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:10:33 d2.utils.events]: \u001b[0m eta: 0:20:42  iter: 239  total_loss: 0.7375  loss_cls: 0.2386  loss_box_reg: 0.3253  loss_rpn_cls: 0.1174  loss_rpn_loc: 0.02562  time: 0.3576  data_time: 0.0027  lr: 5.994e-05  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:10:40 d2.utils.events]: \u001b[0m eta: 0:20:45  iter: 259  total_loss: 0.7272  loss_cls: 0.2377  loss_box_reg: 0.3052  loss_rpn_cls: 0.1567  loss_rpn_loc: 0.01908  time: 0.3588  data_time: 0.0030  lr: 6.4935e-05  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:10:47 d2.utils.events]: \u001b[0m eta: 0:20:33  iter: 279  total_loss: 0.6321  loss_cls: 0.2187  loss_box_reg: 0.2978  loss_rpn_cls: 0.09503  loss_rpn_loc: 0.01544  time: 0.3591  data_time: 0.0026  lr: 6.993e-05  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:10:55 d2.utils.events]: \u001b[0m eta: 0:20:42  iter: 299  total_loss: 0.6694  loss_cls: 0.2214  loss_box_reg: 0.2897  loss_rpn_cls: 0.09057  loss_rpn_loc: 0.0166  time: 0.3597  data_time: 0.0030  lr: 7.4925e-05  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:11:02 d2.utils.events]: \u001b[0m eta: 0:20:38  iter: 319  total_loss: 0.7293  loss_cls: 0.2293  loss_box_reg: 0.3214  loss_rpn_cls: 0.1088  loss_rpn_loc: 0.0151  time: 0.3600  data_time: 0.0030  lr: 7.992e-05  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:11:09 d2.utils.events]: \u001b[0m eta: 0:20:31  iter: 339  total_loss: 0.6438  loss_cls: 0.2211  loss_box_reg: 0.3148  loss_rpn_cls: 0.06484  loss_rpn_loc: 0.01281  time: 0.3609  data_time: 0.0029  lr: 8.4915e-05  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:11:17 d2.utils.events]: \u001b[0m eta: 0:20:22  iter: 359  total_loss: 0.6843  loss_cls: 0.1996  loss_box_reg: 0.3204  loss_rpn_cls: 0.06886  loss_rpn_loc: 0.0119  time: 0.3607  data_time: 0.0029  lr: 8.991e-05  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:11:24 d2.utils.events]: \u001b[0m eta: 0:20:17  iter: 379  total_loss: 0.7664  loss_cls: 0.2154  loss_box_reg: 0.4403  loss_rpn_cls: 0.08976  loss_rpn_loc: 0.03226  time: 0.3615  data_time: 0.0027  lr: 9.4905e-05  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:11:31 d2.utils.events]: \u001b[0m eta: 0:20:09  iter: 399  total_loss: 0.6626  loss_cls: 0.2102  loss_box_reg: 0.3051  loss_rpn_cls: 0.07085  loss_rpn_loc: 0.01687  time: 0.3615  data_time: 0.0031  lr: 9.99e-05  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:11:39 d2.utils.events]: \u001b[0m eta: 0:20:01  iter: 419  total_loss: 0.674  loss_cls: 0.1887  loss_box_reg: 0.3348  loss_rpn_cls: 0.08772  loss_rpn_loc: 0.02929  time: 0.3613  data_time: 0.0029  lr: 0.0001049  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:11:46 d2.utils.events]: \u001b[0m eta: 0:19:53  iter: 439  total_loss: 0.6355  loss_cls: 0.1685  loss_box_reg: 0.3869  loss_rpn_cls: 0.08683  loss_rpn_loc: 0.02516  time: 0.3609  data_time: 0.0029  lr: 0.00010989  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:11:53 d2.utils.events]: \u001b[0m eta: 0:19:45  iter: 459  total_loss: 0.7406  loss_cls: 0.2021  loss_box_reg: 0.4185  loss_rpn_cls: 0.07248  loss_rpn_loc: 0.01774  time: 0.3608  data_time: 0.0028  lr: 0.00011489  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:12:00 d2.utils.events]: \u001b[0m eta: 0:19:38  iter: 479  total_loss: 0.6054  loss_cls: 0.1665  loss_box_reg: 0.317  loss_rpn_cls: 0.07676  loss_rpn_loc: 0.0168  time: 0.3610  data_time: 0.0035  lr: 0.00011988  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:12:07 d2.utils.events]: \u001b[0m eta: 0:19:31  iter: 499  total_loss: 0.514  loss_cls: 0.173  loss_box_reg: 0.2216  loss_rpn_cls: 0.07759  loss_rpn_loc: 0.009171  time: 0.3610  data_time: 0.0028  lr: 0.00012488  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:12:15 d2.utils.events]: \u001b[0m eta: 0:19:23  iter: 519  total_loss: 0.6077  loss_cls: 0.1612  loss_box_reg: 0.3202  loss_rpn_cls: 0.08904  loss_rpn_loc: 0.0178  time: 0.3608  data_time: 0.0030  lr: 0.00012987  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:12:22 d2.utils.events]: \u001b[0m eta: 0:19:15  iter: 539  total_loss: 0.628  loss_cls: 0.1573  loss_box_reg: 0.3576  loss_rpn_cls: 0.07172  loss_rpn_loc: 0.01575  time: 0.3603  data_time: 0.0028  lr: 0.00013487  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:12:29 d2.utils.events]: \u001b[0m eta: 0:19:09  iter: 559  total_loss: 0.6681  loss_cls: 0.1607  loss_box_reg: 0.3417  loss_rpn_cls: 0.07791  loss_rpn_loc: 0.01503  time: 0.3603  data_time: 0.0029  lr: 0.00013986  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:12:36 d2.utils.events]: \u001b[0m eta: 0:18:58  iter: 579  total_loss: 0.5327  loss_cls: 0.1427  loss_box_reg: 0.2755  loss_rpn_cls: 0.04811  loss_rpn_loc: 0.007761  time: 0.3596  data_time: 0.0028  lr: 0.00014486  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:12:42 d2.utils.events]: \u001b[0m eta: 0:18:51  iter: 599  total_loss: 0.6039  loss_cls: 0.1596  loss_box_reg: 0.3183  loss_rpn_cls: 0.05286  loss_rpn_loc: 0.01089  time: 0.3591  data_time: 0.0034  lr: 0.00014985  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:12:50 d2.utils.events]: \u001b[0m eta: 0:18:45  iter: 619  total_loss: 0.5667  loss_cls: 0.1469  loss_box_reg: 0.3331  loss_rpn_cls: 0.05908  loss_rpn_loc: 0.0128  time: 0.3589  data_time: 0.0028  lr: 0.00015485  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:12:57 d2.utils.events]: \u001b[0m eta: 0:18:39  iter: 639  total_loss: 0.6005  loss_cls: 0.1568  loss_box_reg: 0.3111  loss_rpn_cls: 0.07735  loss_rpn_loc: 0.04324  time: 0.3592  data_time: 0.0027  lr: 0.00015984  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:13:04 d2.utils.events]: \u001b[0m eta: 0:18:31  iter: 659  total_loss: 0.5482  loss_cls: 0.1467  loss_box_reg: 0.2593  loss_rpn_cls: 0.0732  loss_rpn_loc: 0.01184  time: 0.3589  data_time: 0.0028  lr: 0.00016484  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:13:11 d2.utils.events]: \u001b[0m eta: 0:18:21  iter: 679  total_loss: 0.5756  loss_cls: 0.1352  loss_box_reg: 0.3028  loss_rpn_cls: 0.06791  loss_rpn_loc: 0.01238  time: 0.3585  data_time: 0.0028  lr: 0.00016983  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:13:18 d2.utils.events]: \u001b[0m eta: 0:18:15  iter: 699  total_loss: 0.5164  loss_cls: 0.1322  loss_box_reg: 0.2585  loss_rpn_cls: 0.054  loss_rpn_loc: 0.01582  time: 0.3587  data_time: 0.0027  lr: 0.00017483  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:13:25 d2.utils.events]: \u001b[0m eta: 0:18:08  iter: 719  total_loss: 0.5212  loss_cls: 0.1591  loss_box_reg: 0.2722  loss_rpn_cls: 0.05611  loss_rpn_loc: 0.02425  time: 0.3587  data_time: 0.0029  lr: 0.00017982  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:13:32 d2.utils.events]: \u001b[0m eta: 0:18:01  iter: 739  total_loss: 0.5201  loss_cls: 0.137  loss_box_reg: 0.2504  loss_rpn_cls: 0.07082  loss_rpn_loc: 0.02006  time: 0.3586  data_time: 0.0030  lr: 0.00018482  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:13:40 d2.utils.events]: \u001b[0m eta: 0:17:55  iter: 759  total_loss: 0.4724  loss_cls: 0.1315  loss_box_reg: 0.2189  loss_rpn_cls: 0.05277  loss_rpn_loc: 0.01636  time: 0.3588  data_time: 0.0028  lr: 0.00018981  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:13:47 d2.utils.events]: \u001b[0m eta: 0:17:48  iter: 779  total_loss: 0.4334  loss_cls: 0.1313  loss_box_reg: 0.2383  loss_rpn_cls: 0.0578  loss_rpn_loc: 0.01952  time: 0.3587  data_time: 0.0027  lr: 0.00019481  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:13:54 d2.utils.events]: \u001b[0m eta: 0:17:37  iter: 799  total_loss: 0.4163  loss_cls: 0.1201  loss_box_reg: 0.2036  loss_rpn_cls: 0.04812  loss_rpn_loc: 0.007774  time: 0.3582  data_time: 0.0028  lr: 0.0001998  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:14:00 d2.utils.events]: \u001b[0m eta: 0:17:26  iter: 819  total_loss: 0.395  loss_cls: 0.1176  loss_box_reg: 0.2109  loss_rpn_cls: 0.05414  loss_rpn_loc: 0.004705  time: 0.3578  data_time: 0.0028  lr: 0.0002048  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:14:07 d2.utils.events]: \u001b[0m eta: 0:17:17  iter: 839  total_loss: 0.5162  loss_cls: 0.1595  loss_box_reg: 0.264  loss_rpn_cls: 0.05313  loss_rpn_loc: 0.009519  time: 0.3575  data_time: 0.0027  lr: 0.00020979  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:14:14 d2.utils.events]: \u001b[0m eta: 0:17:09  iter: 859  total_loss: 0.4247  loss_cls: 0.1248  loss_box_reg: 0.2469  loss_rpn_cls: 0.05389  loss_rpn_loc: 0.00821  time: 0.3573  data_time: 0.0028  lr: 0.00021479  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:14:21 d2.utils.events]: \u001b[0m eta: 0:17:02  iter: 879  total_loss: 0.4249  loss_cls: 0.1167  loss_box_reg: 0.2084  loss_rpn_cls: 0.05759  loss_rpn_loc: 0.01151  time: 0.3571  data_time: 0.0027  lr: 0.00021978  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:14:28 d2.utils.events]: \u001b[0m eta: 0:16:55  iter: 899  total_loss: 0.3969  loss_cls: 0.1207  loss_box_reg: 0.1933  loss_rpn_cls: 0.05552  loss_rpn_loc: 0.01218  time: 0.3571  data_time: 0.0028  lr: 0.00022478  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:14:35 d2.utils.events]: \u001b[0m eta: 0:16:44  iter: 919  total_loss: 0.4864  loss_cls: 0.1281  loss_box_reg: 0.2644  loss_rpn_cls: 0.05758  loss_rpn_loc: 0.009818  time: 0.3570  data_time: 0.0029  lr: 0.00022977  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:14:43 d2.utils.events]: \u001b[0m eta: 0:16:37  iter: 939  total_loss: 0.4835  loss_cls: 0.1378  loss_box_reg: 0.2637  loss_rpn_cls: 0.05676  loss_rpn_loc: 0.01238  time: 0.3568  data_time: 0.0028  lr: 0.00023477  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:14:50 d2.utils.events]: \u001b[0m eta: 0:16:30  iter: 959  total_loss: 0.5039  loss_cls: 0.1432  loss_box_reg: 0.2435  loss_rpn_cls: 0.05887  loss_rpn_loc: 0.03332  time: 0.3567  data_time: 0.0029  lr: 0.00023976  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:14:57 d2.utils.events]: \u001b[0m eta: 0:16:27  iter: 979  total_loss: 0.3878  loss_cls: 0.1174  loss_box_reg: 0.2401  loss_rpn_cls: 0.06454  loss_rpn_loc: 0.01416  time: 0.3570  data_time: 0.0027  lr: 0.00024476  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:15:04 d2.utils.events]: \u001b[0m eta: 0:16:20  iter: 999  total_loss: 0.4758  loss_cls: 0.1254  loss_box_reg: 0.2609  loss_rpn_cls: 0.04144  loss_rpn_loc: 0.02283  time: 0.3570  data_time: 0.0029  lr: 0.00024975  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:15:11 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 1019  total_loss: 0.4352  loss_cls: 0.121  loss_box_reg: 0.1931  loss_rpn_cls: 0.04777  loss_rpn_loc: 0.01078  time: 0.3570  data_time: 0.0031  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:15:18 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 1039  total_loss: 0.3813  loss_cls: 0.1246  loss_box_reg: 0.2014  loss_rpn_cls: 0.03549  loss_rpn_loc: 0.0127  time: 0.3569  data_time: 0.0026  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:15:25 d2.utils.events]: \u001b[0m eta: 0:16:01  iter: 1059  total_loss: 0.4321  loss_cls: 0.1046  loss_box_reg: 0.2419  loss_rpn_cls: 0.03985  loss_rpn_loc: 0.01332  time: 0.3569  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:15:32 d2.utils.events]: \u001b[0m eta: 0:15:52  iter: 1079  total_loss: 0.4363  loss_cls: 0.1143  loss_box_reg: 0.1784  loss_rpn_cls: 0.04912  loss_rpn_loc: 0.01284  time: 0.3566  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:15:39 d2.utils.events]: \u001b[0m eta: 0:15:46  iter: 1099  total_loss: 0.4049  loss_cls: 0.1381  loss_box_reg: 0.2149  loss_rpn_cls: 0.03829  loss_rpn_loc: 0.007382  time: 0.3564  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:15:46 d2.utils.events]: \u001b[0m eta: 0:15:37  iter: 1119  total_loss: 0.3672  loss_cls: 0.1096  loss_box_reg: 0.2018  loss_rpn_cls: 0.04007  loss_rpn_loc: 0.02542  time: 0.3562  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:15:53 d2.utils.events]: \u001b[0m eta: 0:15:30  iter: 1139  total_loss: 0.3881  loss_cls: 0.16  loss_box_reg: 0.1941  loss_rpn_cls: 0.05025  loss_rpn_loc: 0.005927  time: 0.3560  data_time: 0.0030  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:16:00 d2.utils.events]: \u001b[0m eta: 0:15:23  iter: 1159  total_loss: 0.4344  loss_cls: 0.121  loss_box_reg: 0.2093  loss_rpn_cls: 0.05239  loss_rpn_loc: 0.02785  time: 0.3562  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:16:07 d2.utils.events]: \u001b[0m eta: 0:15:11  iter: 1179  total_loss: 0.4353  loss_cls: 0.1144  loss_box_reg: 0.2312  loss_rpn_cls: 0.04066  loss_rpn_loc: 0.01029  time: 0.3560  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:16:14 d2.utils.events]: \u001b[0m eta: 0:15:08  iter: 1199  total_loss: 0.4262  loss_cls: 0.113  loss_box_reg: 0.2274  loss_rpn_cls: 0.04729  loss_rpn_loc: 0.0261  time: 0.3560  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:16:21 d2.utils.events]: \u001b[0m eta: 0:14:57  iter: 1219  total_loss: 0.4911  loss_cls: 0.1356  loss_box_reg: 0.2109  loss_rpn_cls: 0.06172  loss_rpn_loc: 0.01069  time: 0.3558  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:16:29 d2.utils.events]: \u001b[0m eta: 0:14:53  iter: 1239  total_loss: 0.3855  loss_cls: 0.1093  loss_box_reg: 0.1962  loss_rpn_cls: 0.0618  loss_rpn_loc: 0.01588  time: 0.3560  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:16:36 d2.utils.events]: \u001b[0m eta: 0:14:42  iter: 1259  total_loss: 0.3689  loss_cls: 0.1025  loss_box_reg: 0.2138  loss_rpn_cls: 0.02522  loss_rpn_loc: 0.006775  time: 0.3559  data_time: 0.0031  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:16:43 d2.utils.events]: \u001b[0m eta: 0:14:36  iter: 1279  total_loss: 0.4797  loss_cls: 0.1115  loss_box_reg: 0.2445  loss_rpn_cls: 0.05576  loss_rpn_loc: 0.03224  time: 0.3559  data_time: 0.0030  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:16:50 d2.utils.events]: \u001b[0m eta: 0:14:27  iter: 1299  total_loss: 0.3665  loss_cls: 0.1082  loss_box_reg: 0.1985  loss_rpn_cls: 0.04712  loss_rpn_loc: 0.0117  time: 0.3559  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:16:57 d2.utils.events]: \u001b[0m eta: 0:14:17  iter: 1319  total_loss: 0.3888  loss_cls: 0.1001  loss_box_reg: 0.212  loss_rpn_cls: 0.04898  loss_rpn_loc: 0.01851  time: 0.3557  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:17:04 d2.utils.events]: \u001b[0m eta: 0:14:10  iter: 1339  total_loss: 0.3732  loss_cls: 0.1124  loss_box_reg: 0.2202  loss_rpn_cls: 0.03741  loss_rpn_loc: 0.0112  time: 0.3557  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:17:11 d2.utils.events]: \u001b[0m eta: 0:14:04  iter: 1359  total_loss: 0.4228  loss_cls: 0.1155  loss_box_reg: 0.2034  loss_rpn_cls: 0.05265  loss_rpn_loc: 0.009177  time: 0.3558  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:17:18 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 1379  total_loss: 0.3767  loss_cls: 0.107  loss_box_reg: 0.2108  loss_rpn_cls: 0.0458  loss_rpn_loc: 0.0324  time: 0.3559  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:17:25 d2.utils.events]: \u001b[0m eta: 0:13:47  iter: 1399  total_loss: 0.3827  loss_cls: 0.1226  loss_box_reg: 0.1942  loss_rpn_cls: 0.03668  loss_rpn_loc: 0.01404  time: 0.3558  data_time: 0.0030  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:17:33 d2.utils.events]: \u001b[0m eta: 0:13:40  iter: 1419  total_loss: 0.4124  loss_cls: 0.09084  loss_box_reg: 0.2311  loss_rpn_cls: 0.03863  loss_rpn_loc: 0.01521  time: 0.3558  data_time: 0.0027  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:17:40 d2.utils.events]: \u001b[0m eta: 0:13:34  iter: 1439  total_loss: 0.4009  loss_cls: 0.1197  loss_box_reg: 0.19  loss_rpn_cls: 0.04692  loss_rpn_loc: 0.005397  time: 0.3558  data_time: 0.0031  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:17:47 d2.utils.events]: \u001b[0m eta: 0:13:27  iter: 1459  total_loss: 0.3812  loss_cls: 0.1056  loss_box_reg: 0.1904  loss_rpn_cls: 0.04469  loss_rpn_loc: 0.005976  time: 0.3557  data_time: 0.0027  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:17:54 d2.utils.events]: \u001b[0m eta: 0:13:20  iter: 1479  total_loss: 0.4148  loss_cls: 0.1002  loss_box_reg: 0.2126  loss_rpn_cls: 0.04899  loss_rpn_loc: 0.03561  time: 0.3558  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:18:01 d2.utils.events]: \u001b[0m eta: 0:13:12  iter: 1499  total_loss: 0.4103  loss_cls: 0.1253  loss_box_reg: 0.2045  loss_rpn_cls: 0.05171  loss_rpn_loc: 0.0142  time: 0.3557  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:18:08 d2.utils.events]: \u001b[0m eta: 0:13:05  iter: 1519  total_loss: 0.3783  loss_cls: 0.1099  loss_box_reg: 0.179  loss_rpn_cls: 0.03846  loss_rpn_loc: 0.009006  time: 0.3557  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:18:15 d2.utils.events]: \u001b[0m eta: 0:12:58  iter: 1539  total_loss: 0.38  loss_cls: 0.1134  loss_box_reg: 0.2193  loss_rpn_cls: 0.03576  loss_rpn_loc: 0.008734  time: 0.3555  data_time: 0.0027  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:18:22 d2.utils.events]: \u001b[0m eta: 0:12:51  iter: 1559  total_loss: 0.4047  loss_cls: 0.1046  loss_box_reg: 0.2107  loss_rpn_cls: 0.02907  loss_rpn_loc: 0.01737  time: 0.3555  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:18:29 d2.utils.events]: \u001b[0m eta: 0:12:44  iter: 1579  total_loss: 0.376  loss_cls: 0.1007  loss_box_reg: 0.219  loss_rpn_cls: 0.03565  loss_rpn_loc: 0.03371  time: 0.3556  data_time: 0.0030  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:18:36 d2.utils.events]: \u001b[0m eta: 0:12:37  iter: 1599  total_loss: 0.3487  loss_cls: 0.1065  loss_box_reg: 0.1895  loss_rpn_cls: 0.03732  loss_rpn_loc: 0.006108  time: 0.3555  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:18:43 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 1619  total_loss: 0.3859  loss_cls: 0.1027  loss_box_reg: 0.1898  loss_rpn_cls: 0.04141  loss_rpn_loc: 0.01132  time: 0.3555  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:18:51 d2.utils.events]: \u001b[0m eta: 0:12:23  iter: 1639  total_loss: 0.3769  loss_cls: 0.1079  loss_box_reg: 0.2059  loss_rpn_cls: 0.0303  loss_rpn_loc: 0.008425  time: 0.3556  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:18:58 d2.utils.events]: \u001b[0m eta: 0:12:16  iter: 1659  total_loss: 0.3758  loss_cls: 0.1089  loss_box_reg: 0.2026  loss_rpn_cls: 0.04133  loss_rpn_loc: 0.01183  time: 0.3556  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:19:05 d2.utils.events]: \u001b[0m eta: 0:12:09  iter: 1679  total_loss: 0.3902  loss_cls: 0.1014  loss_box_reg: 0.2139  loss_rpn_cls: 0.05383  loss_rpn_loc: 0.01136  time: 0.3556  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:19:12 d2.utils.events]: \u001b[0m eta: 0:12:01  iter: 1699  total_loss: 0.3555  loss_cls: 0.0858  loss_box_reg: 0.1826  loss_rpn_cls: 0.02402  loss_rpn_loc: 0.009459  time: 0.3554  data_time: 0.0033  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:19:19 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 1719  total_loss: 0.3535  loss_cls: 0.08492  loss_box_reg: 0.1858  loss_rpn_cls: 0.03002  loss_rpn_loc: 0.01508  time: 0.3554  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:19:26 d2.utils.events]: \u001b[0m eta: 0:11:46  iter: 1739  total_loss: 0.352  loss_cls: 0.09866  loss_box_reg: 0.1796  loss_rpn_cls: 0.037  loss_rpn_loc: 0.01362  time: 0.3555  data_time: 0.0030  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:19:33 d2.utils.events]: \u001b[0m eta: 0:11:38  iter: 1759  total_loss: 0.3662  loss_cls: 0.1081  loss_box_reg: 0.1895  loss_rpn_cls: 0.03646  loss_rpn_loc: 0.01197  time: 0.3556  data_time: 0.0030  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:19:40 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 1779  total_loss: 0.327  loss_cls: 0.09252  loss_box_reg: 0.1792  loss_rpn_cls: 0.032  loss_rpn_loc: 0.009644  time: 0.3555  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:19:47 d2.utils.events]: \u001b[0m eta: 0:11:25  iter: 1799  total_loss: 0.3827  loss_cls: 0.1208  loss_box_reg: 0.1993  loss_rpn_cls: 0.02826  loss_rpn_loc: 0.00671  time: 0.3553  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:19:54 d2.utils.events]: \u001b[0m eta: 0:11:17  iter: 1819  total_loss: 0.3918  loss_cls: 0.1097  loss_box_reg: 0.1886  loss_rpn_cls: 0.03348  loss_rpn_loc: 0.01017  time: 0.3553  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:20:01 d2.utils.events]: \u001b[0m eta: 0:11:10  iter: 1839  total_loss: 0.3706  loss_cls: 0.1049  loss_box_reg: 0.2197  loss_rpn_cls: 0.04278  loss_rpn_loc: 0.02391  time: 0.3552  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:20:08 d2.utils.events]: \u001b[0m eta: 0:11:03  iter: 1859  total_loss: 0.3396  loss_cls: 0.1064  loss_box_reg: 0.1647  loss_rpn_cls: 0.02967  loss_rpn_loc: 0.01555  time: 0.3551  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:20:15 d2.utils.events]: \u001b[0m eta: 0:10:56  iter: 1879  total_loss: 0.4018  loss_cls: 0.1097  loss_box_reg: 0.1985  loss_rpn_cls: 0.04165  loss_rpn_loc: 0.0186  time: 0.3552  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:20:22 d2.utils.events]: \u001b[0m eta: 0:10:49  iter: 1899  total_loss: 0.3489  loss_cls: 0.1101  loss_box_reg: 0.199  loss_rpn_cls: 0.03207  loss_rpn_loc: 0.009785  time: 0.3552  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:20:30 d2.utils.events]: \u001b[0m eta: 0:10:43  iter: 1919  total_loss: 0.3791  loss_cls: 0.1087  loss_box_reg: 0.1973  loss_rpn_cls: 0.04511  loss_rpn_loc: 0.01221  time: 0.3554  data_time: 0.0030  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:20:37 d2.utils.events]: \u001b[0m eta: 0:10:37  iter: 1939  total_loss: 0.4283  loss_cls: 0.09475  loss_box_reg: 0.2425  loss_rpn_cls: 0.04105  loss_rpn_loc: 0.01914  time: 0.3555  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:20:44 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 1959  total_loss: 0.369  loss_cls: 0.1123  loss_box_reg: 0.186  loss_rpn_cls: 0.02747  loss_rpn_loc: 0.007  time: 0.3553  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:20:51 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 1979  total_loss: 0.4134  loss_cls: 0.1304  loss_box_reg: 0.2139  loss_rpn_cls: 0.03368  loss_rpn_loc: 0.01246  time: 0.3552  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:20:58 d2.utils.events]: \u001b[0m eta: 0:10:14  iter: 1999  total_loss: 0.3599  loss_cls: 0.0809  loss_box_reg: 0.1849  loss_rpn_cls: 0.02903  loss_rpn_loc: 0.01463  time: 0.3553  data_time: 0.0031  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:21:05 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 2019  total_loss: 0.382  loss_cls: 0.09224  loss_box_reg: 0.2171  loss_rpn_cls: 0.02779  loss_rpn_loc: 0.01349  time: 0.3553  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:21:13 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 2039  total_loss: 0.4653  loss_cls: 0.1002  loss_box_reg: 0.2195  loss_rpn_cls: 0.06815  loss_rpn_loc: 0.03778  time: 0.3554  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:21:20 d2.utils.events]: \u001b[0m eta: 0:09:53  iter: 2059  total_loss: 0.3745  loss_cls: 0.09328  loss_box_reg: 0.1948  loss_rpn_cls: 0.04124  loss_rpn_loc: 0.007512  time: 0.3555  data_time: 0.0027  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:21:27 d2.utils.events]: \u001b[0m eta: 0:09:47  iter: 2079  total_loss: 0.4623  loss_cls: 0.09702  loss_box_reg: 0.1997  loss_rpn_cls: 0.03518  loss_rpn_loc: 0.01002  time: 0.3555  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:21:34 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 2099  total_loss: 0.3316  loss_cls: 0.09583  loss_box_reg: 0.155  loss_rpn_cls: 0.03177  loss_rpn_loc: 0.007636  time: 0.3554  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:21:41 d2.utils.events]: \u001b[0m eta: 0:09:34  iter: 2119  total_loss: 0.3659  loss_cls: 0.1048  loss_box_reg: 0.1896  loss_rpn_cls: 0.04103  loss_rpn_loc: 0.02806  time: 0.3555  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:21:48 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 2139  total_loss: 0.3499  loss_cls: 0.09026  loss_box_reg: 0.1918  loss_rpn_cls: 0.02643  loss_rpn_loc: 0.01242  time: 0.3556  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:21:55 d2.utils.events]: \u001b[0m eta: 0:09:19  iter: 2159  total_loss: 0.3181  loss_cls: 0.1017  loss_box_reg: 0.1669  loss_rpn_cls: 0.02191  loss_rpn_loc: 0.009749  time: 0.3555  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:22:02 d2.utils.events]: \u001b[0m eta: 0:09:13  iter: 2179  total_loss: 0.3665  loss_cls: 0.09899  loss_box_reg: 0.1992  loss_rpn_cls: 0.03262  loss_rpn_loc: 0.01224  time: 0.3555  data_time: 0.0027  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:22:10 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 2199  total_loss: 0.3748  loss_cls: 0.08387  loss_box_reg: 0.2099  loss_rpn_cls: 0.0304  loss_rpn_loc: 0.01318  time: 0.3555  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:22:16 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 2219  total_loss: 0.3387  loss_cls: 0.09989  loss_box_reg: 0.1924  loss_rpn_cls: 0.01901  loss_rpn_loc: 0.01987  time: 0.3554  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:22:24 d2.utils.events]: \u001b[0m eta: 0:08:50  iter: 2239  total_loss: 0.3038  loss_cls: 0.1005  loss_box_reg: 0.1715  loss_rpn_cls: 0.031  loss_rpn_loc: 0.008044  time: 0.3554  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:22:31 d2.utils.events]: \u001b[0m eta: 0:08:44  iter: 2259  total_loss: 0.3334  loss_cls: 0.09059  loss_box_reg: 0.1517  loss_rpn_cls: 0.03199  loss_rpn_loc: 0.02222  time: 0.3554  data_time: 0.0030  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:22:38 d2.utils.events]: \u001b[0m eta: 0:08:36  iter: 2279  total_loss: 0.3548  loss_cls: 0.09837  loss_box_reg: 0.1962  loss_rpn_cls: 0.0253  loss_rpn_loc: 0.01003  time: 0.3553  data_time: 0.0027  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:22:45 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 2299  total_loss: 0.3282  loss_cls: 0.1002  loss_box_reg: 0.172  loss_rpn_cls: 0.03077  loss_rpn_loc: 0.005585  time: 0.3553  data_time: 0.0030  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:22:52 d2.utils.events]: \u001b[0m eta: 0:08:24  iter: 2319  total_loss: 0.3491  loss_cls: 0.1285  loss_box_reg: 0.1768  loss_rpn_cls: 0.01955  loss_rpn_loc: 0.004194  time: 0.3553  data_time: 0.0026  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:22:59 d2.utils.events]: \u001b[0m eta: 0:08:16  iter: 2339  total_loss: 0.3112  loss_cls: 0.09365  loss_box_reg: 0.1408  loss_rpn_cls: 0.0331  loss_rpn_loc: 0.01285  time: 0.3552  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:23:06 d2.utils.events]: \u001b[0m eta: 0:08:08  iter: 2359  total_loss: 0.3473  loss_cls: 0.09404  loss_box_reg: 0.1697  loss_rpn_cls: 0.02715  loss_rpn_loc: 0.009002  time: 0.3551  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:23:13 d2.utils.events]: \u001b[0m eta: 0:08:01  iter: 2379  total_loss: 0.3746  loss_cls: 0.0783  loss_box_reg: 0.17  loss_rpn_cls: 0.03086  loss_rpn_loc: 0.03404  time: 0.3551  data_time: 0.0027  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:23:20 d2.utils.events]: \u001b[0m eta: 0:07:54  iter: 2399  total_loss: 0.3419  loss_cls: 0.1047  loss_box_reg: 0.1983  loss_rpn_cls: 0.0275  loss_rpn_loc: 0.008631  time: 0.3550  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:23:27 d2.utils.events]: \u001b[0m eta: 0:07:47  iter: 2419  total_loss: 0.2831  loss_cls: 0.0756  loss_box_reg: 0.1661  loss_rpn_cls: 0.02622  loss_rpn_loc: 0.009502  time: 0.3550  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:23:34 d2.utils.events]: \u001b[0m eta: 0:07:40  iter: 2439  total_loss: 0.3388  loss_cls: 0.1042  loss_box_reg: 0.1796  loss_rpn_cls: 0.01567  loss_rpn_loc: 0.006852  time: 0.3550  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:23:41 d2.utils.events]: \u001b[0m eta: 0:07:33  iter: 2459  total_loss: 0.3696  loss_cls: 0.09086  loss_box_reg: 0.1953  loss_rpn_cls: 0.0286  loss_rpn_loc: 0.01854  time: 0.3550  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:23:48 d2.utils.events]: \u001b[0m eta: 0:07:26  iter: 2479  total_loss: 0.3989  loss_cls: 0.08332  loss_box_reg: 0.2139  loss_rpn_cls: 0.03041  loss_rpn_loc: 0.01464  time: 0.3550  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:23:55 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 2499  total_loss: 0.3055  loss_cls: 0.088  loss_box_reg: 0.1447  loss_rpn_cls: 0.04226  loss_rpn_loc: 0.00814  time: 0.3550  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:24:02 d2.utils.events]: \u001b[0m eta: 0:07:11  iter: 2519  total_loss: 0.3676  loss_cls: 0.09842  loss_box_reg: 0.2047  loss_rpn_cls: 0.03611  loss_rpn_loc: 0.01631  time: 0.3550  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:24:09 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 2539  total_loss: 0.3241  loss_cls: 0.09088  loss_box_reg: 0.1627  loss_rpn_cls: 0.02681  loss_rpn_loc: 0.01102  time: 0.3549  data_time: 0.0031  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:24:16 d2.utils.events]: \u001b[0m eta: 0:06:57  iter: 2559  total_loss: 0.3244  loss_cls: 0.08752  loss_box_reg: 0.1676  loss_rpn_cls: 0.02999  loss_rpn_loc: 0.01121  time: 0.3549  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:24:23 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 2579  total_loss: 0.3368  loss_cls: 0.08294  loss_box_reg: 0.17  loss_rpn_cls: 0.04116  loss_rpn_loc: 0.02197  time: 0.3549  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:24:30 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 2599  total_loss: 0.3159  loss_cls: 0.08859  loss_box_reg: 0.1573  loss_rpn_cls: 0.03788  loss_rpn_loc: 0.005886  time: 0.3549  data_time: 0.0030  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:24:37 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 2619  total_loss: 0.395  loss_cls: 0.09845  loss_box_reg: 0.1747  loss_rpn_cls: 0.04055  loss_rpn_loc: 0.009875  time: 0.3548  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:24:45 d2.utils.events]: \u001b[0m eta: 0:06:28  iter: 2639  total_loss: 0.3333  loss_cls: 0.0931  loss_box_reg: 0.1587  loss_rpn_cls: 0.03407  loss_rpn_loc: 0.009309  time: 0.3549  data_time: 0.0027  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:24:52 d2.utils.events]: \u001b[0m eta: 0:06:22  iter: 2659  total_loss: 0.3588  loss_cls: 0.09779  loss_box_reg: 0.1821  loss_rpn_cls: 0.0359  loss_rpn_loc: 0.01405  time: 0.3550  data_time: 0.0031  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:24:59 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 2679  total_loss: 0.3412  loss_cls: 0.09152  loss_box_reg: 0.1702  loss_rpn_cls: 0.02778  loss_rpn_loc: 0.008765  time: 0.3550  data_time: 0.0027  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:25:06 d2.utils.events]: \u001b[0m eta: 0:06:08  iter: 2699  total_loss: 0.3401  loss_cls: 0.08447  loss_box_reg: 0.1869  loss_rpn_cls: 0.0349  loss_rpn_loc: 0.01015  time: 0.3549  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:25:13 d2.utils.events]: \u001b[0m eta: 0:06:01  iter: 2719  total_loss: 0.3126  loss_cls: 0.1027  loss_box_reg: 0.1697  loss_rpn_cls: 0.02954  loss_rpn_loc: 0.006036  time: 0.3549  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:25:20 d2.utils.events]: \u001b[0m eta: 0:05:54  iter: 2739  total_loss: 0.28  loss_cls: 0.07599  loss_box_reg: 0.1601  loss_rpn_cls: 0.0233  loss_rpn_loc: 0.008151  time: 0.3550  data_time: 0.0027  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:25:27 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 2759  total_loss: 0.3216  loss_cls: 0.09761  loss_box_reg: 0.1761  loss_rpn_cls: 0.03158  loss_rpn_loc: 0.007361  time: 0.3550  data_time: 0.0030  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:25:35 d2.utils.events]: \u001b[0m eta: 0:05:42  iter: 2779  total_loss: 0.3372  loss_cls: 0.08176  loss_box_reg: 0.1653  loss_rpn_cls: 0.03064  loss_rpn_loc: 0.01771  time: 0.3550  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:25:42 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 2799  total_loss: 0.3835  loss_cls: 0.09478  loss_box_reg: 0.1679  loss_rpn_cls: 0.03523  loss_rpn_loc: 0.01842  time: 0.3550  data_time: 0.0027  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:25:49 d2.utils.events]: \u001b[0m eta: 0:05:29  iter: 2819  total_loss: 0.3732  loss_cls: 0.08973  loss_box_reg: 0.1812  loss_rpn_cls: 0.0438  loss_rpn_loc: 0.01478  time: 0.3551  data_time: 0.0026  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:25:56 d2.utils.events]: \u001b[0m eta: 0:05:22  iter: 2839  total_loss: 0.3729  loss_cls: 0.1133  loss_box_reg: 0.1998  loss_rpn_cls: 0.02573  loss_rpn_loc: 0.01199  time: 0.3551  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:26:03 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 2859  total_loss: 0.2682  loss_cls: 0.07552  loss_box_reg: 0.1407  loss_rpn_cls: 0.02386  loss_rpn_loc: 0.009634  time: 0.3551  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:26:10 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 2879  total_loss: 0.3013  loss_cls: 0.08632  loss_box_reg: 0.1781  loss_rpn_cls: 0.03064  loss_rpn_loc: 0.01271  time: 0.3550  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:26:17 d2.utils.events]: \u001b[0m eta: 0:05:01  iter: 2899  total_loss: 0.3066  loss_cls: 0.09481  loss_box_reg: 0.1458  loss_rpn_cls: 0.02037  loss_rpn_loc: 0.007004  time: 0.3550  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:26:24 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 2919  total_loss: 0.3666  loss_cls: 0.1007  loss_box_reg: 0.1975  loss_rpn_cls: 0.03038  loss_rpn_loc: 0.01808  time: 0.3549  data_time: 0.0027  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:26:31 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 2939  total_loss: 0.3948  loss_cls: 0.09037  loss_box_reg: 0.2002  loss_rpn_cls: 0.03243  loss_rpn_loc: 0.03866  time: 0.3548  data_time: 0.0030  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:26:38 d2.utils.events]: \u001b[0m eta: 0:04:39  iter: 2959  total_loss: 0.3395  loss_cls: 0.09067  loss_box_reg: 0.1686  loss_rpn_cls: 0.03203  loss_rpn_loc: 0.01498  time: 0.3549  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:26:45 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 2979  total_loss: 0.3605  loss_cls: 0.101  loss_box_reg: 0.1922  loss_rpn_cls: 0.02591  loss_rpn_loc: 0.008701  time: 0.3548  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:26:52 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 2999  total_loss: 0.3444  loss_cls: 0.08308  loss_box_reg: 0.1675  loss_rpn_cls: 0.02912  loss_rpn_loc: 0.007756  time: 0.3547  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:26:59 d2.utils.events]: \u001b[0m eta: 0:04:17  iter: 3019  total_loss: 0.2803  loss_cls: 0.08738  loss_box_reg: 0.1572  loss_rpn_cls: 0.02496  loss_rpn_loc: 0.006009  time: 0.3546  data_time: 0.0027  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:27:06 d2.utils.events]: \u001b[0m eta: 0:04:09  iter: 3039  total_loss: 0.3292  loss_cls: 0.09454  loss_box_reg: 0.177  loss_rpn_cls: 0.02849  loss_rpn_loc: 0.01161  time: 0.3546  data_time: 0.0030  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:27:13 d2.utils.events]: \u001b[0m eta: 0:04:02  iter: 3059  total_loss: 0.2729  loss_cls: 0.07277  loss_box_reg: 0.1488  loss_rpn_cls: 0.02286  loss_rpn_loc: 0.01564  time: 0.3546  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:27:20 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 3079  total_loss: 0.2948  loss_cls: 0.08065  loss_box_reg: 0.1713  loss_rpn_cls: 0.01689  loss_rpn_loc: 0.0132  time: 0.3546  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:27:27 d2.utils.events]: \u001b[0m eta: 0:03:47  iter: 3099  total_loss: 0.3008  loss_cls: 0.09839  loss_box_reg: 0.1372  loss_rpn_cls: 0.03074  loss_rpn_loc: 0.007056  time: 0.3546  data_time: 0.0026  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:27:34 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 3119  total_loss: 0.3216  loss_cls: 0.0899  loss_box_reg: 0.1929  loss_rpn_cls: 0.03326  loss_rpn_loc: 0.02062  time: 0.3546  data_time: 0.0027  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:27:41 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 3139  total_loss: 0.2821  loss_cls: 0.06591  loss_box_reg: 0.1648  loss_rpn_cls: 0.01647  loss_rpn_loc: 0.007768  time: 0.3546  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:27:48 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 3159  total_loss: 0.347  loss_cls: 0.09154  loss_box_reg: 0.1868  loss_rpn_cls: 0.0303  loss_rpn_loc: 0.008394  time: 0.3546  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:27:55 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 3179  total_loss: 0.3562  loss_cls: 0.08872  loss_box_reg: 0.1934  loss_rpn_cls: 0.03097  loss_rpn_loc: 0.01215  time: 0.3545  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:28:02 d2.utils.events]: \u001b[0m eta: 0:03:12  iter: 3199  total_loss: 0.3289  loss_cls: 0.0939  loss_box_reg: 0.1681  loss_rpn_cls: 0.04068  loss_rpn_loc: 0.009061  time: 0.3545  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:28:09 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 3219  total_loss: 0.3147  loss_cls: 0.08425  loss_box_reg: 0.1494  loss_rpn_cls: 0.02627  loss_rpn_loc: 0.008907  time: 0.3545  data_time: 0.0027  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:28:16 d2.utils.events]: \u001b[0m eta: 0:02:58  iter: 3239  total_loss: 0.3596  loss_cls: 0.0815  loss_box_reg: 0.19  loss_rpn_cls: 0.03264  loss_rpn_loc: 0.01577  time: 0.3545  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:28:23 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 3259  total_loss: 0.3388  loss_cls: 0.08346  loss_box_reg: 0.197  loss_rpn_cls: 0.02358  loss_rpn_loc: 0.01718  time: 0.3544  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:28:30 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 3279  total_loss: 0.3253  loss_cls: 0.088  loss_box_reg: 0.1887  loss_rpn_cls: 0.01789  loss_rpn_loc: 0.01148  time: 0.3544  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:28:37 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 3299  total_loss: 0.3723  loss_cls: 0.1035  loss_box_reg: 0.1854  loss_rpn_cls: 0.02652  loss_rpn_loc: 0.006256  time: 0.3544  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:28:45 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 3319  total_loss: 0.3863  loss_cls: 0.09052  loss_box_reg: 0.1955  loss_rpn_cls: 0.04246  loss_rpn_loc: 0.01964  time: 0.3544  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:28:52 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 3339  total_loss: 0.3379  loss_cls: 0.09668  loss_box_reg: 0.1759  loss_rpn_cls: 0.03067  loss_rpn_loc: 0.01102  time: 0.3544  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:28:59 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 3359  total_loss: 0.301  loss_cls: 0.08548  loss_box_reg: 0.1397  loss_rpn_cls: 0.03571  loss_rpn_loc: 0.0192  time: 0.3545  data_time: 0.0030  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:29:06 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 3379  total_loss: 0.2601  loss_cls: 0.07364  loss_box_reg: 0.1739  loss_rpn_cls: 0.02043  loss_rpn_loc: 0.005773  time: 0.3544  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:29:13 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 3399  total_loss: 0.3554  loss_cls: 0.08944  loss_box_reg: 0.1978  loss_rpn_cls: 0.02444  loss_rpn_loc: 0.006561  time: 0.3544  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:29:20 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 3419  total_loss: 0.366  loss_cls: 0.08652  loss_box_reg: 0.2052  loss_rpn_cls: 0.04145  loss_rpn_loc: 0.02156  time: 0.3544  data_time: 0.0026  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:29:27 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 3439  total_loss: 0.3191  loss_cls: 0.08757  loss_box_reg: 0.17  loss_rpn_cls: 0.02857  loss_rpn_loc: 0.01346  time: 0.3544  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:29:34 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 3459  total_loss: 0.357  loss_cls: 0.08497  loss_box_reg: 0.1582  loss_rpn_cls: 0.02347  loss_rpn_loc: 0.009081  time: 0.3545  data_time: 0.0030  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:29:42 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 3479  total_loss: 0.2868  loss_cls: 0.08293  loss_box_reg: 0.1544  loss_rpn_cls: 0.02553  loss_rpn_loc: 0.02766  time: 0.3545  data_time: 0.0026  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:29:49 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 3499  total_loss: 0.3213  loss_cls: 0.06423  loss_box_reg: 0.1729  loss_rpn_cls: 0.03062  loss_rpn_loc: 0.01154  time: 0.3545  data_time: 0.0030  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:29:56 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 3519  total_loss: 0.2815  loss_cls: 0.07939  loss_box_reg: 0.1653  loss_rpn_cls: 0.02193  loss_rpn_loc: 0.007268  time: 0.3545  data_time: 0.0027  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:30:03 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 3539  total_loss: 0.3403  loss_cls: 0.09618  loss_box_reg: 0.163  loss_rpn_cls: 0.02477  loss_rpn_loc: 0.00742  time: 0.3544  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:30:10 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 3559  total_loss: 0.3463  loss_cls: 0.09456  loss_box_reg: 0.166  loss_rpn_cls: 0.04262  loss_rpn_loc: 0.04381  time: 0.3545  data_time: 0.0034  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:30:17 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 3579  total_loss: 0.2968  loss_cls: 0.06222  loss_box_reg: 0.1494  loss_rpn_cls: 0.02518  loss_rpn_loc: 0.01601  time: 0.3545  data_time: 0.0028  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:30:24 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 3599  total_loss: 0.2798  loss_cls: 0.07303  loss_box_reg: 0.1382  loss_rpn_cls: 0.02393  loss_rpn_loc: 0.01151  time: 0.3545  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:30:32 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 3619  total_loss: 0.3233  loss_cls: 0.08574  loss_box_reg: 0.1725  loss_rpn_cls: 0.02268  loss_rpn_loc: 0.008094  time: 0.3546  data_time: 0.0036  lr: 0.00025  max_mem: 2125M\n",
      "\u001b[32m[08/28 08:30:39 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 3639  total_loss: 0.2825  loss_cls: 0.07168  loss_box_reg: 0.1536  loss_rpn_cls: 0.01805  loss_rpn_loc: 0.01185  time: 0.3547  data_time: 0.0029  lr: 0.00025  max_mem: 2125M\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "wandb.init(sync_tensorboard=True,name='baseline')\n",
    "model = 'COCO-Detection/faster_rcnn_R_50_C4_1x.yaml'\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(get_config_file(model))\n",
    "cfg.DATASETS.TRAIN = ('data',)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.MODEL.WEIGHTS = get_checkpoint_url(model)\n",
    "cfg.SOLVER.MAX_ITER = 2500 + 1250\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(['PathHole'])\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.475\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "img = cv2.imread('./data/img-1.jpg')\n",
    "predictor = DefaultPredictor(cfg)\n",
    "preds = predictor(img)['instances'].to('cpu')\n",
    "v = Visualizer(img[:,:,::-1],metadata=metadata,scale=1)\n",
    "v = v.draw_instance_predictions(preds)\n",
    "v = v.get_image()[:,:,::-1]\n",
    "wandb.log({'img':wandb.Image(v)})\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(v)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe8f281-5ecc-4fe3-87b3-bee62ab633c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from detectron2.checkpoint import DetectionCheckpointer\n",
    "# checkpointer = DetectionCheckpointer(model, save_dir=\"output\")\n",
    "# checkpointer.save(\"model_999\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b59a6-3c72-4f5d-aab3-4a65b9edcdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'faster_rcnn_R_101_C4_3x.yaml',\n",
    "    'faster_rcnn_R_101_DC5_3x.yaml',\n",
    "    'faster_rcnn_R_101_FPN_3x.yaml',\n",
    "    'faster_rcnn_R_50_C4_1x.yaml',\n",
    "    'faster_rcnn_R_50_C4_3x.yaml',\n",
    "    'faster_rcnn_R_50_DC5_1x.yaml',\n",
    "    'faster_rcnn_R_50_DC5_3x.yaml',\n",
    "    'faster_rcnn_R_50_FPN_1x.yaml',\n",
    "    'faster_rcnn_R_50_FPN_3x.yaml',\n",
    "    'faster_rcnn_X_101_32x8d_FPN_3x.yaml',\n",
    "    'faster_rcnn_R_101_DC5_3x.yaml'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ba5564-716c-44e8-a16f-3487da1b9cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_LRS = [\n",
    "    0.00025,\n",
    "    0.00050,\n",
    "    0.00075,\n",
    "    0.0001,\n",
    "    0.001,\n",
    "    0.01,\n",
    "    0.0002,\n",
    "    0.0003,\n",
    "    0.0004,\n",
    "    0.0005,\n",
    "    0.0006,\n",
    "    0.0007,\n",
    "    0.0008,\n",
    "    0.0009,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e47dcce-25ae-4bcf-a4aa-9ef646a2dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMS_PER_BATCHS = [\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    6,\n",
    "    7,\n",
    "    8,\n",
    "    9,\n",
    "    10\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f12ce8-5e01-4ca5-88b5-c1fd18e55cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_PER_IMAGES = [\n",
    "    121,\n",
    "    122,\n",
    "    123,\n",
    "    124,\n",
    "    125,\n",
    "    126,\n",
    "    127,\n",
    "    129\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e34dc-77cb-4c23-8b04-fcae0e497ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.init(sync_tensorboard=True,name=model)\n",
    "    model = model\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(get_config_file(model))\n",
    "    cfg.DATASETS.TRAIN = ('data',)\n",
    "    cfg.DATASETS.TEST = ()\n",
    "    cfg.MODEL.WEIGHTS = get_checkpoint_url(model)\n",
    "    cfg.SOLVER.MAX_ITER = 2500 + 1250\n",
    "    cfg.SOLVER.BASE_LR = 0.00025\n",
    "    cfg.SOLVER.STEPS = []\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(['PathHole'])\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "    trainer = DefaultTrainer(cfg)\n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.train()\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.475\n",
    "    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "    img = cv2.imread('./data/img-1.jpg')\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    preds = predictor(img)['instances'].to('cpu')\n",
    "    v = Visualizer(img[:,:,::-1],metadata=metadata,scale=1)\n",
    "    v = v.draw_instance_predictions(preds)\n",
    "    v = v.get_image()[:,:,::-1]\n",
    "    wandb.log({'img':wandb.Image(v)})\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.imshow(v)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6451cf97-9a48-4942-848e-7ec500075f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for BASE_LR in BASE_LRS:\n",
    "#     torch.cuda.empty_cache()\n",
    "#     wandb.init(sync_tensorboard=True,name=model)\n",
    "#     model = \n",
    "#     cfg = get_cfg()\n",
    "#     cfg.merge_from_file(get_config_file(model))\n",
    "#     cfg.DATASETS.TRAIN = ('data',)\n",
    "#     cfg.DATASETS.TEST = ()\n",
    "#     cfg.MODEL.WEIGHTS = get_checkpoint_url(model)\n",
    "#     cfg.SOLVER.MAX_ITER = 2500 + 1250\n",
    "#     cfg.SOLVER.BASE_LR = BASE_LR\n",
    "#     cfg.SOLVER.STEPS = []\n",
    "#     cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "#     cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(['PathHole'])\n",
    "#     cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "#     trainer = DefaultTrainer(cfg)\n",
    "#     trainer.resume_or_load(resume=False)\n",
    "#     trainer.train()\n",
    "#     cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.475\n",
    "#     cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "#     img = cv2.imread('./data/img-1.jpg')\n",
    "#     predictor = DefaultPredictor(cfg)\n",
    "#     preds = predictor(img)['instances'].to('cpu')\n",
    "#     v = Visualizer(img[:,:,::-1],metadata=metadata,scale=1)\n",
    "#     v = v.draw_instance_predictions(preds)\n",
    "#     v = v.get_image()[:,:,::-1]\n",
    "#     wandb.log({'img':wandb.Image(v)})\n",
    "#     plt.figure(figsize=(10,7))\n",
    "#     plt.imshow(v)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dccb7da-32db-4e82-843f-c3244e2f9859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for IMS_PER_BATCH in IMS_PER_BATCHS:\n",
    "#     torch.cuda.empty_cache()\n",
    "#     wandb.init(sync_tensorboard=True,name=model)\n",
    "#     model = \n",
    "#     cfg = get_cfg()\n",
    "#     cfg.merge_from_file(get_config_file(model))\n",
    "#     cfg.DATASETS.TRAIN = ('data',)\n",
    "#     cfg.DATASETS.TEST = ()\n",
    "#     cfg.MODEL.WEIGHTS = get_checkpoint_url(model)\n",
    "#     cfg.SOLVER.MAX_ITER = 2500 + 1250\n",
    "#     cfg.SOLVER.BASE_LR = \n",
    "#     cfg.SOLVER.STEPS = []\n",
    "#     cfg.SOLVER.IMS_PER_BATCH = IMS_PER_BATCH\n",
    "#     cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(['PathHole'])\n",
    "#     cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "#     trainer = DefaultTrainer(cfg)\n",
    "#     trainer.resume_or_load(resume=False)\n",
    "#     trainer.train()\n",
    "#     cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.475\n",
    "#     cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "#     img = cv2.imread('./data/img-1.jpg')\n",
    "#     predictor = DefaultPredictor(cfg)\n",
    "#     preds = predictor(img)['instances'].to('cpu')\n",
    "#     v = Visualizer(img[:,:,::-1],metadata=metadata,scale=1)\n",
    "#     v = v.draw_instance_predictions(preds)\n",
    "#     v = v.get_image()[:,:,::-1]\n",
    "#     wandb.log({'img':wandb.Image(v)})\n",
    "#     plt.figure(figsize=(10,7))\n",
    "#     plt.imshow(v)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289a6194-fb72-4e8c-b3e7-8dbcf697e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for BATCH_SIZE_PER_IMAGE in BATCH_SIZE_PER_IMAGES:\n",
    "#     torch.cuda.empty_cache()\n",
    "#     wandb.init(sync_tensorboard=True,name=model)\n",
    "#     model = \n",
    "#     cfg = get_cfg()\n",
    "#     cfg.merge_from_file(get_config_file(model))\n",
    "#     cfg.DATASETS.TRAIN = ('data',)\n",
    "#     cfg.DATASETS.TEST = ()\n",
    "#     cfg.MODEL.WEIGHTS = get_checkpoint_url(model)\n",
    "#     cfg.SOLVER.MAX_ITER = 2500 + 1250\n",
    "#     cfg.SOLVER.BASE_LR = \n",
    "#     cfg.SOLVER.STEPS = []\n",
    "#     cfg.SOLVER.IMS_PER_BATCH = IMS_PER_BATCH\n",
    "#     cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(['PathHole'])\n",
    "#     cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = BATCH_SIZE_PER_IMAGE\n",
    "#     trainer = DefaultTrainer(cfg)\n",
    "#     trainer.resume_or_load(resume=False)\n",
    "#     trainer.train()\n",
    "#     cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.475\n",
    "#     cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "#     img = cv2.imread('./data/img-1.jpg')\n",
    "#     predictor = DefaultPredictor(cfg)\n",
    "#     preds = predictor(img)['instances'].to('cpu')\n",
    "#     v = Visualizer(img[:,:,::-1],metadata=metadata,scale=1)\n",
    "#     v = v.draw_instance_predictions(preds)\n",
    "#     v = v.get_image()[:,:,::-1]\n",
    "#     wandb.log({'img':wandb.Image(v)})\n",
    "#     plt.figure(figsize=(10,7))\n",
    "#     plt.imshow(v)\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python373jvsc74a57bd0210f9608a45c0278a93c9e0b10db32a427986ab48cfc0d20c139811eb78c4bbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
