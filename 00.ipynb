{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae79578-788a-40a1-bf42-89eaf57e1337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,cv2,torch,torchvision\n",
    "import detectron2\n",
    "from detectron2.evaluation import COCOEvaluator,inference_context,inference_on_dataset\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import DatasetCatalog,MetadataCatalog,build_detection_test_loader\n",
    "from detectron2.engine import DefaultPredictor,DefaultTrainer\n",
    "from detectron2.model_zoo import get_checkpoint_url,get_config_file\n",
    "from detectron2.utils.video_visualizer import VideoVisualizer\n",
    "from detectron2.utils.visualizer import Visualizer,BoxMode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from xml.etree import ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb81c213-fd8d-42dc-808a-f8cb02cd286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "x_mins = []\n",
    "y_mins = []\n",
    "y_maxs = []\n",
    "x_maxs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f3ef2f-2f53-4119-bdf4-1e36ae3d4810",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in zip(os.listdir('./data/')):\n",
    "    try:\n",
    "        img = img[0]\n",
    "        tree = ElementTree.parse(f'./data/{img}')\n",
    "        root = tree.getroot()\n",
    "        for box in root.findall('.//bndbox'):\n",
    "            xmin = box.find('xmin').text\n",
    "            xmax = box.find('xmax').text\n",
    "            ymin = box.find('ymin').text\n",
    "            ymax = box.find('ymax').text\n",
    "        imgs.append('./data/' + img.replace('.xml','.jpg'))\n",
    "        x_mins.append(int(xmin))\n",
    "        x_maxs.append(int(xmax))\n",
    "        y_mins.append(int(ymin))\n",
    "        y_maxs.append(int(ymax))\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3acc5d63-8890-4af9-a5e7-9ab58152c416",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'frame':imgs,'xmin':x_mins,'xmax':x_maxs,'ymax':y_maxs,'ymin':y_mins})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f15a90e-795f-4e82-8bc6-dac6ed18439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data=data):\n",
    "    dataset = []\n",
    "    for idx in tqdm(range(len(data))):\n",
    "        record = {}\n",
    "        info = data.iloc[idx]\n",
    "        xmin,ymin,xmax,ymax = info['xmin'],info['ymin'],info['xmax'],info['ymax']\n",
    "        height,width = cv2.imread(info['frame']).shape[:2]\n",
    "        record['file_name'] = info['frame']\n",
    "        record['height'] = height\n",
    "        record['width'] = width\n",
    "        info['class_id'] = 0\n",
    "        record['cateogry_id'] = 0\n",
    "        objs = [{'bbox':[info['xmin'],info['ymin'],info['xmax'],info['ymax']],'bbox_mode':BoxMode.XYXY_ABS,'iscrowd':0,'category_id':0}]\n",
    "        record['image_id'] = idx\n",
    "        record['annotations'] = objs\n",
    "        record['class_id'] = 0\n",
    "        record['xmin'] = xmin\n",
    "        record['ymin'] = ymin\n",
    "        record['xmax'] = xmax\n",
    "        record['ymax'] = ymax\n",
    "        dataset.append(record)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0db9aef3-bad4-4ad1-a282-c8dacb65de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetCatalog.register('data',lambda : load_data())\n",
    "MetadataCatalog.get('data').set(thing_classes=['PathHole'])\n",
    "metadata = MetadataCatalog.get('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78d4d1fd-0174-4ba7-bf2c-da83ec47f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "380d3188-2304-49e6-bfc0-52d72dc18dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5e13211-513b-4027-8d2c-619b38891f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# wandb.init(sync_tensorboard=True,name='baseline')\n",
    "# model = 'COCO-Detection/faster_rcnn_R_50_C4_1x.yaml'\n",
    "# cfg = get_cfg()\n",
    "# cfg.merge_from_file(get_config_file(model))\n",
    "# cfg.DATASETS.TRAIN = ('data',)\n",
    "# cfg.DATASETS.TEST = ()\n",
    "# cfg.MODEL.WEIGHTS = get_checkpoint_url(model)\n",
    "# cfg.SOLVER.MAX_ITER = 2500 + 1250\n",
    "# cfg.SOLVER.BASE_LR = 0.00025\n",
    "# cfg.SOLVER.STEPS = []\n",
    "# cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "# cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(['PathHole'])\n",
    "# cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "# trainer = DefaultTrainer(cfg)\n",
    "# trainer.resume_or_load(resume=False)\n",
    "# trainer.train()\n",
    "# cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.475\n",
    "# cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "# img = cv2.imread('./data/img-1.jpg')\n",
    "# predictor = DefaultPredictor(cfg)\n",
    "# preds = predictor(img)['instances'].to('cpu')\n",
    "# v = Visualizer(img[:,:,::-1],metadata=metadata,scale=1)\n",
    "# v = v.draw_instance_predictions(preds)\n",
    "# v = v.get_image()[:,:,::-1]\n",
    "# wandb.log({'img':wandb.Image(v)})\n",
    "# plt.figure(figsize=(10,7))\n",
    "# plt.imshow(v)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fe8f281-5ecc-4fe3-87b3-bee62ab633c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from detectron2.checkpoint import DetectionCheckpointer\n",
    "# checkpointer = DetectionCheckpointer(model, save_dir=\"output\")\n",
    "# checkpointer.save(\"model_999\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "924b59a6-3c72-4f5d-aab3-4a65b9edcdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'COCO-Detection/faster_rcnn_R_101_C4_3x.yaml',\n",
    "    'COCO-Detection/faster_rcnn_R_101_DC5_3x.yaml',\n",
    "    'COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml',\n",
    "    'COCO-Detection/faster_rcnn_R_50_C4_1x.yaml',\n",
    "    'COCO-Detection/faster_rcnn_R_50_C4_3x.yaml',\n",
    "    'COCO-Detection/faster_rcnn_R_50_DC5_1x.yaml',\n",
    "    'COCO-Detection/faster_rcnn_R_50_DC5_3x.yaml',\n",
    "    'COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml',\n",
    "    'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',\n",
    "    'COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml',\n",
    "    'COCO-Detection/faster_rcnn_R_101_DC5_3x.yaml'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71ba5564-716c-44e8-a16f-3487da1b9cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_LRS = [\n",
    "    0.00025,\n",
    "    0.00050,\n",
    "    0.00075,\n",
    "    0.0001,\n",
    "    0.001,\n",
    "    0.01,\n",
    "    0.0002,\n",
    "    0.0003,\n",
    "    0.0004,\n",
    "    0.0005,\n",
    "    0.0006,\n",
    "    0.0007,\n",
    "    0.0008,\n",
    "    0.0009,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e47dcce-25ae-4bcf-a4aa-9ef646a2dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMS_PER_BATCHS = [\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    6,\n",
    "    7,\n",
    "    8,\n",
    "    9,\n",
    "    10\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43f12ce8-5e01-4ca5-88b5-c1fd18e55cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_PER_IMAGES = [\n",
    "    121,\n",
    "    122,\n",
    "    123,\n",
    "    124,\n",
    "    125,\n",
    "    126,\n",
    "    127,\n",
    "    129\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c0e34dc-77cb-4c23-8b04-fcae0e497ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in models:\n",
    "#     try:\n",
    "#         torch.cuda.empty_cache()\n",
    "#         wandb.init(sync_tensorboard=True,name=model)\n",
    "#         model = model\n",
    "#         cfg = get_cfg()\n",
    "#         cfg.merge_from_file(get_config_file(model))\n",
    "#         cfg.DATASETS.TRAIN = ('data',)\n",
    "#         cfg.DATASETS.TEST = ()\n",
    "#         cfg.MODEL.WEIGHTS = get_checkpoint_url(model)\n",
    "#         cfg.SOLVER.MAX_ITER = 2500 + 1250\n",
    "#         cfg.SOLVER.BASE_LR = 0.00025\n",
    "#         cfg.SOLVER.STEPS = []\n",
    "#         cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "#         cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(['PathHole'])\n",
    "#         cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "#         trainer = DefaultTrainer(cfg)\n",
    "#         trainer.resume_or_load(resume=False)\n",
    "#         trainer.train()\n",
    "#         cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.475\n",
    "#         cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "#         img = cv2.imread('./data/img-1.jpg')\n",
    "#         predictor = DefaultPredictor(cfg)\n",
    "#         preds = predictor(img)['instances'].to('cpu')\n",
    "#         v = Visualizer(img[:,:,::-1],metadata=metadata,scale=1)\n",
    "#         v = v.draw_instance_predictions(preds)\n",
    "#         v = v.get_image()[:,:,::-1]\n",
    "#         wandb.log({'img':wandb.Image(v)})\n",
    "#         plt.figure(figsize=(10,7))\n",
    "#         plt.imshow(v)\n",
    "#         plt.show()\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49a36d3a-5293-4b10-9940-ae03fb32fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'COCO-Detection/faster_rcnn_R_101_C4_3x.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6451cf97-9a48-4942-848e-7ec500075f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for BASE_LR in BASE_LRS:\n",
    "#     torch.cuda.empty_cache()\n",
    "#     wandb.init(sync_tensorboard=True,name=f'{BASE_LR}')\n",
    "#     cfg = get_cfg()\n",
    "#     cfg.merge_from_file(get_config_file(model))\n",
    "#     cfg.DATASETS.TRAIN = ('data',)\n",
    "#     cfg.DATASETS.TEST = ()\n",
    "#     cfg.MODEL.WEIGHTS = get_checkpoint_url(model)\n",
    "#     cfg.SOLVER.MAX_ITER = 2500 + 1250\n",
    "#     cfg.SOLVER.BASE_LR = BASE_LR\n",
    "#     cfg.SOLVER.STEPS = []\n",
    "#     cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "#     cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(['PathHole'])\n",
    "#     cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "#     trainer = DefaultTrainer(cfg)\n",
    "#     trainer.resume_or_load(resume=False)\n",
    "#     trainer.train()\n",
    "#     cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.475\n",
    "#     cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "#     img = cv2.imread('./data/img-1.jpg')\n",
    "#     predictor = DefaultPredictor(cfg)\n",
    "#     preds = predictor(img)['instances'].to('cpu')\n",
    "#     v = Visualizer(img[:,:,::-1],metadata=metadata,scale=1)\n",
    "#     v = v.draw_instance_predictions(preds)\n",
    "#     v = v.get_image()[:,:,::-1]\n",
    "#     wandb.log({'img':wandb.Image(v)})\n",
    "#     plt.figure(figsize=(10,7))\n",
    "#     plt.imshow(v)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dccb7da-32db-4e82-843f-c3244e2f9859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for IMS_PER_BATCH in IMS_PER_BATCHS:\n",
    "#     torch.cuda.empty_cache()\n",
    "#     wandb.init(sync_tensorboard=True,name=model)\n",
    "#     model = \n",
    "#     cfg = get_cfg()\n",
    "#     cfg.merge_from_file(get_config_file(model))\n",
    "#     cfg.DATASETS.TRAIN = ('data',)\n",
    "#     cfg.DATASETS.TEST = ()\n",
    "#     cfg.MODEL.WEIGHTS = get_checkpoint_url(model)\n",
    "#     cfg.SOLVER.MAX_ITER = 2500 + 1250\n",
    "#     cfg.SOLVER.BASE_LR = \n",
    "#     cfg.SOLVER.STEPS = []\n",
    "#     cfg.SOLVER.IMS_PER_BATCH = IMS_PER_BATCH\n",
    "#     cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(['PathHole'])\n",
    "#     cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "#     trainer = DefaultTrainer(cfg)\n",
    "#     trainer.resume_or_load(resume=False)\n",
    "#     trainer.train()\n",
    "#     cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.475\n",
    "#     cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "#     img = cv2.imread('./data/img-1.jpg')\n",
    "#     predictor = DefaultPredictor(cfg)\n",
    "#     preds = predictor(img)['instances'].to('cpu')\n",
    "#     v = Visualizer(img[:,:,::-1],metadata=metadata,scale=1)\n",
    "#     v = v.draw_instance_predictions(preds)\n",
    "#     v = v.get_image()[:,:,::-1]\n",
    "#     wandb.log({'img':wandb.Image(v)})\n",
    "#     plt.figure(figsize=(10,7))\n",
    "#     plt.imshow(v)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289a6194-fb72-4e8c-b3e7-8dbcf697e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for BATCH_SIZE_PER_IMAGE in BATCH_SIZE_PER_IMAGES:\n",
    "#     torch.cuda.empty_cache()\n",
    "#     wandb.init(sync_tensorboard=True,name=model)\n",
    "#     model = \n",
    "#     cfg = get_cfg()\n",
    "#     cfg.merge_from_file(get_config_file(model))\n",
    "#     cfg.DATASETS.TRAIN = ('data',)\n",
    "#     cfg.DATASETS.TEST = ()\n",
    "#     cfg.MODEL.WEIGHTS = get_checkpoint_url(model)\n",
    "#     cfg.SOLVER.MAX_ITER = 2500 + 1250\n",
    "#     cfg.SOLVER.BASE_LR = \n",
    "#     cfg.SOLVER.STEPS = []\n",
    "#     cfg.SOLVER.IMS_PER_BATCH = IMS_PER_BATCH\n",
    "#     cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(['PathHole'])\n",
    "#     cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = BATCH_SIZE_PER_IMAGE\n",
    "#     trainer = DefaultTrainer(cfg)\n",
    "#     trainer.resume_or_load(resume=False)\n",
    "#     trainer.train()\n",
    "#     cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.475\n",
    "#     cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "#     img = cv2.imread('./data/img-1.jpg')\n",
    "#     predictor = DefaultPredictor(cfg)\n",
    "#     preds = predictor(img)['instances'].to('cpu')\n",
    "#     v = Visualizer(img[:,:,::-1],metadata=metadata,scale=1)\n",
    "#     v = v.draw_instance_predictions(preds)\n",
    "#     v = v.get_image()[:,:,::-1]\n",
    "#     wandb.log({'img':wandb.Image(v)})\n",
    "#     plt.figure(figsize=(10,7))\n",
    "#     plt.imshow(v)\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python373jvsc74a57bd0210f9608a45c0278a93c9e0b10db32a427986ab48cfc0d20c139811eb78c4bbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
